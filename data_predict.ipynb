{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b0ad03-ee72-4569-979e-635a80cf906a",
   "metadata": {},
   "source": [
    "# Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32381427-e6f5-4e35-9da1-daecf9cf3b21",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa289a4-9228-4c52-8a9e-e77edc4d1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4f886-2d93-471a-909b-a927a0054732",
   "metadata": {},
   "source": [
    "#### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95004ff6-17c7-44db-9fe0-df0b4e120d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = None\n",
    "temp_image = 'temp.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278d712-ab05-400b-9f64-7d9b11cdd68c",
   "metadata": {},
   "source": [
    "### Resize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ad0622-2d28-4354-bc7e-583306a05c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImage(imageName):\n",
    "    img = Image.open(imageName)\n",
    "    img = img.resize((100, 89), Image.ANTIALIAS)\n",
    "    img.save(imageName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814ed39-6763-441d-b092-ed874bf8bc14",
   "metadata": {},
   "source": [
    "## Running Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8a72d7-65d5-4e66-8997-b24d9ac0d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_avg(img, weight):\n",
    "    global bg\n",
    "    if bg is None:\n",
    "        bg = img.copy().astype(\"float\")\n",
    "        return\n",
    "    cv2.accumulateWeighted(img, bg, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab182e7e-4969-4848-8a50-a75fdb1b640e",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b03573c-9153-4c4e-8f3c-b12ff80399da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(image):\n",
    "    global bg\n",
    "    sub_image = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
    "\n",
    "    thresholded = cv2.threshold(sub_image,0,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    (contor, hier) = cv2.findContours(thresholded.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(contor) == 0:\n",
    "        return\n",
    "    else:\n",
    "        segmented = max(contor, key=cv2.contourArea)\n",
    "        return (thresholded, segmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0451bc4-7ee2-46c5-b22b-1e77947ecef4",
   "metadata": {},
   "source": [
    "## Getting Predicted Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c59766-1eb1-4c82-b16b-af6e813208b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictedClass():\n",
    "    image = cv2.imread(temp_image)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = gray_image.reshape(89, 100, 1)\n",
    "    gray_image = np.array([gray_image])\n",
    "    prediction = model.predict(gray_image)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63518f98-7500-42c4-93b5-98e4f71cccba",
   "metadata": {},
   "source": [
    "## Displaying Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a619a8cb-419b-4e3b-a3e4-b147a0bf4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showStatistics(prediction,textImage):\n",
    "    gestures = ['fist', 'palm', 'swing']\n",
    "    n = len(gestures)\n",
    "    x = 30\n",
    "    y =  30\n",
    "    height = (n+3)*y\n",
    "    width = 500\n",
    "        \n",
    "    predicted_gesture = gestures[np.argmax(prediction)]\n",
    "    sum = 0.00\n",
    "    for i in prediction[0]:\n",
    "        sum += i\n",
    "    confidence = (np.amax(prediction) /  sum) * 100\n",
    "    \n",
    "    cv2.putText(textImage,\"Gesture: \" + predicted_gesture,(x, y),cv2.FONT_HERSHEY_SIMPLEX,1,(255, 23, 25),2)\n",
    "    y += 30\n",
    "    cv2.putText(textImage,\"Confidence: \" + str(\"{:.2f}\".format(confidence)) + \"%\",(x, y),cv2.FONT_HERSHEY_SIMPLEX,1,(23, 255, 25),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024781f-6e0a-49f5-bed1-80724279ac1f",
   "metadata": {},
   "source": [
    "## Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885048ff-82d4-4129-9af3-cd532c4726dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "method1 = False\n",
    "\n",
    "if method1:\n",
    "    import os\n",
    "    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    gpu_options.allow_growth = True\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "#\n",
    "method2 = False\n",
    "\n",
    "if method2:\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "    tf.compat.v1.keras.backend.set_session(\n",
    "        tf.compat.v1.Session(config=config))\n",
    "\n",
    "# \n",
    "method3 = False\n",
    "\n",
    "if method3:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a247faac-4b27-4e4f-8170-1e4871e6c96f",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769a2239-195a-4f4c-9b00-3be00cba76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "model = models.load_model('./TrainedModel/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8650b9-b60f-4485-bdf4-fe8c4b07984c",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b6a5d3b-39ba-4c1b-990a-25c2c59f6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aWeight = 0.5\n",
    "top, right, bottom, left = 30, 350, 225, 590\n",
    "num_frames = 0\n",
    "start_recording = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce79b521-a127-4a44-929a-a1b95851241b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_18780\\2905944500.py:3: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((100, 89), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    grabbed, frame = camera.read()\n",
    "\n",
    "    if grabbed:\n",
    "        frame = imutils.resize(frame, width=700)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    \n",
    "        roi = frame[top:bottom, right:left]\n",
    "\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "        if num_frames < 30:\n",
    "            run_avg(gray, aWeight)\n",
    "        else:\n",
    "            hand = segment(gray)\n",
    "\n",
    "            if hand is not None:\n",
    "                (thresholded, segmented) = hand\n",
    "\n",
    "                cv2.drawContours(frame, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "                if start_recording:\n",
    "                    cv2.imwrite(temp_image, thresholded)\n",
    "                    resizeImage(temp_image)\n",
    "                    prediction = getPredictedClass()\n",
    "                    showStatistics(prediction,frame)\n",
    "\n",
    "                cv2.imshow(\"Thesholded\", thresholded)\n",
    "\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        num_frames += 1\n",
    "        cv2.imshow(\"Video Feed\", frame)\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "        if keypress == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print(\"Error, Please check your camera\")\n",
    "        print(camera)\n",
    "        break\n",
    "\n",
    "# relaease the resources\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed0a4452-2008-48e6-94bd-f56ad858a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove temporary image file\n",
    "import os\n",
    "os.remove(temp_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
